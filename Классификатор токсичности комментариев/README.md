# <p style="text-align: center;"> Классификация токсичности комментариев </p>

**В данном проекте мы создадим классификаторы токсичности комментариев на основе XGBoost, LightGBM, CatBoostClassifier, LogisticRegression и выберем из них лучший**

**Описание данных:**
- text — содержание комментария 
- toxic — токсичный комментарий или нет
    
**Для решения задачи:** 
    - изучим датасет и проведем предобработку естественного языка
    - обучим классификаторы и выберем из них лучший
    - сделаем вывод по результатам исследования


**Для выполнения проекта использовались библиотеки:**  
- *Pandas*  
- *Numpy*    
- *Re*  
- *NLTK*  
- *Sklearn*  
- *Xgboost*  
- *Catboost*  
- *Lightgbm*  


**ПО результатам работы:**  
- мы применили такие процедуры предобработки текста как лемматизация,удаление знаков препинания и спец. символов при помощи регулярных выражений, а так же выбрасывали стоп слова и переводили текст в векторный вид для обучения моделей;  
- в качестве бейслайна был выбран DummyClassifier с стратегией слепого угадывания, который показал очень низкую вероятность отгадать класс, все модели показали много лучший результат, что свидетельствует об их адекватности;  
- в качестве основной модели выбрали LGBM как самый быстро обучающийся бустер дающий необходимую точность из условий задания, альтернативно можно использовать логистическую регрессию, которая так же показала отличные результаты в данной задаче.
